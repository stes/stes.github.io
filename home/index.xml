<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Homes on Steffen Schneider</title>
    <link>https://stes.io/home/</link>
    <description>Recent content in Homes on Steffen Schneider</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 - 2019 Steffen Schneider</copyright>
    <lastBuildDate>Thu, 05 Oct 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://stes.io/home/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title></title>
      <link>https://stes.io/home/about/</link>
      <pubDate>Thu, 05 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://stes.io/home/about/</guid>
      <description>My goal is to build machine learning models capable of approaching the performance of biological brains in terms of data-efficiency and robustness to perturbations and changes in their environment. Drawing inspiration from adaptation behaviour of biological systems, I study methods for domain adaptation, transfer learning and semi-supervised learning.
I&amp;rsquo;m currently working on self-supervised representation learning for speech processing with Michael Auli, Alexei Baevski and Ronan Collobert at Facebook AI Research.</description>
    </item>
    
    <item>
      <title>News</title>
      <link>https://stes.io/home/news/</link>
      <pubDate>Thu, 05 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://stes.io/home/news/</guid>
      <description>2019
 Our paper wav2vec: Unsupervised Pre-training for Speech Recognition was accepted at Interspeech 2019. We also released the code for pre-training wav2vec embeddings as part of fairseq. Our paper Iron-Sequestering Nanocompartments as Multiplexed Electron Microscopy Gene Reporters is forthcoming in ACS Nano, with a pre-print available on bioRxiv. In our new paper wav2vec: Unsupervised Pre-training for Speech Recognition, we demonstrate that self-supervised learning of acoustic embeddings improves speech recognition over purely supervised approaches and sets a new state-of-the art performance on the TIMIT phoneme recognition and Wall Street Journal speech recognition benchmarks.</description>
    </item>
    
    <item>
      <title>Research and Teaching</title>
      <link>https://stes.io/home/roles/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://stes.io/home/roles/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Extracurriculars</title>
      <link>https://stes.io/home/extracurriculars/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://stes.io/home/extracurriculars/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Publications and Talks</title>
      <link>https://stes.io/home/publications/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://stes.io/home/publications/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Projects</title>
      <link>https://stes.io/home/projects/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://stes.io/home/projects/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Homes on Steffen Schneider</title>
    <link>https://stes.io/home/</link>
    <description>Recent content in Homes on Steffen Schneider</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 - 2019 Steffen Schneider</copyright>
    <lastBuildDate>Thu, 05 Oct 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://stes.io/home/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title></title>
      <link>https://stes.io/home/about/</link>
      <pubDate>Thu, 05 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://stes.io/home/about/</guid>
      <description>My goal is to build machine learning models capable of approaching the performance of biological brains in terms of data-efficiency and robustness to perturbations and changes in their environment. Drawing inspiration from adaptation behaviour of biological systems, I study methods for domain adaptation, transfer learning and semi-supervised learning.
Besides, I am interested in applications to medical image processing, neuroscience and, as of now, in speech processing at Facebook AI Research with Michael Auli and Ronan Collobert.</description>
    </item>
    
    <item>
      <title>News</title>
      <link>https://stes.io/home/news/</link>
      <pubDate>Thu, 05 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://stes.io/home/news/</guid>
      <description>2019
 In our new paper wav2vec: Unsupervised Pre-training for Speech Recognition, we demonstrate that self-supervised learning of acoustic embeddings improves speech recognition over purely supervised approaches and sets a new state-of-the art on TIMIT and Wall Street Journal.  2018
 Our paper on Multi-Task Generalization and Adaptation between Noisy Digit Datasets was accepted for a poster presentation at the Continual Learning Workshop at NIPS 2018. We just released a PyTorch toolbox for Semi-supervised Adaptive Learning Across Domains (salad) for a fair and reproducible evaluation of current domain adaptation algorithms.</description>
    </item>
    
    <item>
      <title>Research and Teaching</title>
      <link>https://stes.io/home/roles/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://stes.io/home/roles/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Extracurriculars</title>
      <link>https://stes.io/home/extracurriculars/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://stes.io/home/extracurriculars/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Publications and Talks</title>
      <link>https://stes.io/home/publications/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://stes.io/home/publications/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Projects</title>
      <link>https://stes.io/home/projects/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://stes.io/home/projects/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
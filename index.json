[{"authors":["admin"],"categories":null,"content":"My goal is to build machine learning tools and statistical methods for decompiling intelligent behavior. In my research group at Helmholtz Munich, we develop machine learning algorithms for representation learning and inference of nonlinear system dynamics, study how large and multi-modal biological datasets can be compressed into foundation models, and study their mechanistic interpretability.\nIf you are looking for opportunities for a position as PhD student, postdoc, research engineer, research assistant, or an internship, Bachelor or Master\u0026rsquo;s thesis, have a look at my past work and student projects and ping me if you\u0026rsquo;re interested in working with us.\nI pursued my doctoral studies at the Swiss Federal Institute of Technology Lausanne (EPFL) and the International Max Planck Research School for Intelligent Systems, advised by Mackenzie Mathis and Matthias Bethge in the ELLIS PhD \u0026amp; PostDoc program.\nDuring my PhD, I also worked as a Research Scientist Intern advised by Laurens van der Maaten and Ishan Misra on multimodal representation learning in the FAIR team at Meta NYC, and at Amazon Web Services in Tübingen as an Applied Science Intern where I worked on self-learning and object centric representations with Peter Gehler, Bernhard Schölkopf and Matthias Bethge.\nPrior to starting my PhD, I worked on wav2vec and vq-wav2vec, two self-supervised representation learning algorithms for speech processing with Michael Auli, Alexei Baevski and Ronan Collobert at Facebook AI Research in Menlo Park, CA.\nAside from my research, I\u0026rsquo;m a strong supporter of exposing children to modern computer science topics early on during their school education. That\u0026rsquo;s why I co-founded and advised IT4Kids to teach CS in elementary school, KI macht Schule to teach AI and Machine Learning fundamentals in high school and helped organizing the German National Competition in AI for high school students. If you want to join our team at KI macht Schule and bring AI education to every school in Germany, Austria and Switzerland, don\u0026rsquo;t hesitate to reach out!\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://stes.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"My goal is to build machine learning tools and statistical methods for decompiling intelligent behavior. In my research group at Helmholtz Munich, we develop machine learning algorithms for representation learning and inference of nonlinear system dynamics, study how large and multi-modal biological datasets can be compressed into foundation models, and study their mechanistic interpretability.\nIf you are looking for opportunities for a position as PhD student, postdoc, research engineer, research assistant, or an internship, Bachelor or Master\u0026rsquo;s thesis, have a look at my past work and student projects and ping me if you\u0026rsquo;re interested in working with us.","tags":null,"title":"Steffen Schneider","type":"authors"},{"authors":["Steffen Schneider"],"categories":null,"content":"","date":1705449600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1705449600,"objectID":"0f40cf545adf79432be77d9037b7794b","permalink":"https://stes.io/publication/thesis/","publishdate":"2024-01-17T00:00:00Z","relpermalink":"/publication/thesis/","section":"publication","summary":"PhD Thesis","tags":null,"title":"Robust machine learning for neuroscientific inference","type":"publication"},{"authors":["Steffen Schneider*","Jin H Lee*","Mackenzie W Mathis"],"categories":null,"content":"","date":1648771200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648771200,"objectID":"b1fc8f4fa380ad74b8d84e955a2d630a","permalink":"https://stes.io/publication/cebra/","publishdate":"2022-04-01T00:00:00Z","relpermalink":"/publication/cebra/","section":"publication","summary":"CEBRA is a contrastive learning algorithm for relating behavior and neural activity.","tags":null,"title":"Learnable Latent Embeddings for Joint Behavioral and Neural Analysis","type":"publication"},{"authors":["Roland S Zimmermann*","Yash Sharma*","Steffen Schneider*","Matthias Bethge","Wieland Brendel"],"categories":null,"content":"","date":1623715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623715200,"objectID":"004df15ff0378e61167a260dcf6bb97e","permalink":"https://stes.io/publication/cl_ica/","publishdate":"2021-06-15T00:00:00Z","relpermalink":"/publication/cl_ica/","section":"publication","summary":"Contrastive learning with the InfoNCE objective can recover the ground truth latent factors underlying the data.","tags":null,"title":"Contrastive Learning Inverts the Data Generating Process","type":"publication"},{"authors":["Alexander Mathis","Steffen Schneider","Jessy Lauer","Mackenzie Mathis"],"categories":null,"content":"","date":1602633600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602633600,"objectID":"f22009e1400be3f120873376827d23df","permalink":"https://stes.io/publication/primer/","publishdate":"2020-10-14T00:00:00Z","relpermalink":"/publication/primer/","section":"publication","summary":"We discuss principles of pose estimation algorithms and highlight their potential and pitfalls for experimentalists.","tags":null,"title":"A Primer on Motion Capture with Deep Learning: Principles, Pitfalls and Perspectives","type":"publication"},{"authors":["Steffen Schneider*","Evgenia Rusak*","Luisa Eck","Oliver Bringmann","Wieland Brendel","Matthias Bethge"],"categories":null,"content":"","date":1593475200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593475200,"objectID":"918507e3128c971ff1e2c1c80e9f952a","permalink":"https://stes.io/publication/batchadapt/","publishdate":"2020-06-30T00:00:00Z","relpermalink":"/publication/batchadapt/","section":"publication","summary":"Adapting batch norm statistics of trained computer vision models considerably increases robustness at test-time.","tags":null,"title":"Improving Robustness against Common Corruptions by Covariate Shift Adaptation","type":"publication"},{"authors":["Alexei Baevski*","Steffen Schneider*","Michael Auli"],"categories":null,"content":"","date":1570838400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570838400,"objectID":"7d5f5878f16dbdce4d1defae76a2f785","permalink":"https://stes.io/publication/vqwav2vec/","publishdate":"2019-10-12T00:00:00Z","relpermalink":"/publication/vqwav2vec/","section":"publication","summary":"Learning discrete representations of speech yields state-of-the-art recognition performance on TIMIT and WSJ.","tags":null,"title":"vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations","type":"publication"},{"authors":["Felix Sigmund","Susanne Pettinger","Massimo Kube","Fabian Schneider","Martina Schifferer","Steffen Schneider","Maria V Efremova","Jesús Pujol-Martí","Michaela Aichler","Axel Walch","Thomas Misgeld","Hendrik Dietz","Gil Gregor Westmeyer"],"categories":null,"content":"","date":1559865600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559865600,"objectID":"35b8eb3febd144dcd29def8bf13362c1","permalink":"https://stes.io/publication/nano/","publishdate":"2019-06-07T00:00:00Z","relpermalink":"/publication/nano/","section":"publication","summary":"Multicolored gene reporters for light microscopy are indispensable for biomedical research, but equivalent genetic tools for electron microscopy (EM) are still rare despite the increasing importance of nanometer resolution for reverse engineering of molecular machinery and reliable mapping of cellular circuits. We here introduce the fully genetic encapsulin/cargo system of Quasibacillus thermotolerans (Qt), which in combination with the recently characterized encapsulin system from Myxococcus xanthus (Mx) enables multiplexed gene reporter imaging via conventional transmission electron microscopy (TEM) in mammalian cells. Cryo-electron reconstructions revealed that the Qt encapsulin shell self-assembles to nanospheres with T = 4 icosahedral symmetry and a diameter of ∼43 nm harboring two putative pore regions at the 5-fold and 3-fold axes. We also found that upon heterologous expression in mammalian cells, the native cargo is autotargeted to the inner surface of the shell and exhibits ferroxidase activity leading to efficient intraluminal iron biomineralization, which enhances cellular TEM contrast. We furthermore demonstrate that the two differently sized encapsulins of Qt and Mx do not intermix and can be robustly differentiated by conventional TEM via a deep learning classifier to enable automated multiplexed EM gene reporter imaging.","tags":null,"title":"Iron-Sequestering Nanocompartments as Multiplexed Electron Microscopy Gene Reporters","type":"publication"},{"authors":["Steffen Schneider","Alexei Baevski","Ronan Collobert","Michael Auli"],"categories":null,"content":"","date":1554940800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554940800,"objectID":"7781d5785ef561158f202da710c0a3dd","permalink":"https://stes.io/publication/wav2vec/","publishdate":"2019-04-11T00:00:00Z","relpermalink":"/publication/wav2vec/","section":"publication","summary":"Contrastive pre-training on speech at scale reduces the need for labeled data.","tags":null,"title":"wav2vec: Unsupervised Pre-training for Speech Recognition","type":"publication"},{"authors":["Steffen Schneider","Alexander S. Ecker","Jakob H. Macke","Matthias Bethge"],"categories":[],"content":"","date":1538345632,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579644832,"objectID":"e108626d66e8a2eefac255fc0834d8aa","permalink":"https://stes.io/publication/multitask/","publishdate":"2018-09-30T23:13:52+01:00","relpermalink":"/publication/multitask/","section":"publication","summary":"Transfer learning for adaptation to new tasks is usually performed by either fine-tuning all model parameters or parameters in the final layers. We show that good target performance can also be achieved on typical domain adaptation tasks by adapting only the normalization statistics and affine transformations of feature maps throughout the network. We apply this adaptation scheme to supervised domain adaptation on common digit datasets and study robustness properties under perturbation by noise. Our results indicate that (1) adaptation to noise exceeds the difficulty of widely used digit benchmarks in domain adaptation, (2) the similarity of the optimal adaptation parameters for different domains is strongly predictive of generalization performance, and (3) generalization performance is highest with training on a rich environment or high noise levels.","tags":[],"title":"Multi-Task Generalization and Adaptation between Noisy Digit Datasets: An Empirical Study","type":"publication"},{"authors":["Steffen Schneider","Alexander S. Ecker","Jakob H. Macke","Matthias Bethge"],"categories":null,"content":"","date":1538265600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538265600,"objectID":"788a213612aa554375ec6bb929de3314","permalink":"https://stes.io/publication/salad/","publishdate":"2018-09-30T00:00:00Z","relpermalink":"/publication/salad/","section":"publication","summary":"We introduce salad, an open source toolbox that provides a unified implementation of state-of-the-art methods for transfer learning, semi-supervised learning and domain adaptation. In the first release, we provide a framework for reproducing, extending and combining research results of the past years, including model architectures, loss functions and training algorithms. The toolbox along with first benchmark results and further resources is accessible at domainadaptation.org.","tags":null,"title":"Salad: A Toolbox for Semi-supervised Adaptive Learning Across Domains","type":"publication"},{"authors":["Akara Supratak","Steffen Schneider","Hao Dong","Ling Li","Yike Guo"],"categories":null,"content":"","date":1512345600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512345600,"objectID":"e70f8b58fd189122896679d3be32d9d6","permalink":"https://stes.io/publication/nipstimeseries/","publishdate":"2017-12-04T00:00:00Z","relpermalink":"/publication/nipstimeseries/","section":"publication","summary":"This study presents a novel data-driven approach to detect desynchronization among biosignals from two modalities. We propose to train a deep neural network to learn synchronized patterns between biosignals from two modalities by transcribing signals from one modality into their expected, simultaneous or synchronized signal in another modality. Thus, instead of measuring the degree of synchrony between signals from different modalities using traditional linear and non-linear measures, we simplify this problem into the problem of measuring the degree of synchrony between the real and the synthesized signals from the same modality using the traditional measures. Desynchronization detection is then achieved by applying a threshold function to the estimated degree of synchrony. We demonstrate the approach with the detection of eye-movement artifacts in a public sleep dataset and compare the detection performance with traditional approaches.","tags":null,"title":"Towards Desynchronization Detection in Biosignals","type":"publication"},{"authors":["Panagiotis Symvoulidis","Antonella Lauri","Anca Stefanoiu","Michele Cappetta","Steffen Schneider","Hongbo Jia","Anja Stelzl","Maximilian Koch","Carlos Cruz Perez","Ahne Myklatun","Sabine Renninger","Andriy Chmyrov","Tobias Lasser","Wolfgang Wurst","Vasilis Ntziachristos","Gil G Westmeyer"],"categories":null,"content":"","date":1506902400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1506902400,"objectID":"4b989b9aba5a2a913440ec5844c59fa3","permalink":"https://stes.io/publication/neubtracker/","publishdate":"2017-10-02T00:00:00Z","relpermalink":"/publication/neubtracker/","section":"publication","summary":"A long-standing objective in neuroscience has been to image distributed neuronal activity in freely behaving animals. Here we introduce NeuBtracker, a tracking microscope for simultaneous imaging of neuronal activity and behavior of freely swimming fluorescent reporter fish. We showcase the value of NeuBtracker for screening neurostimulants with respect to their combined neuronal and behavioral effects and for determining spontaneous and stimulus-induced spatiotemporal patterns of neuronal activation during naturalistic behavior.","tags":null,"title":"NeuBtracker — imaging neurobehavioral dynamics in freely behaving fish","type":"publication"},{"authors":["Daniel Bug","Steffen Schneider","Anne Grote","Eva Oswald","Friedrich Feuerhake","Julia Schüler","Dorit Merhof"],"categories":null,"content":"","date":1505347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505347200,"objectID":"2d7db15601200c99bc0a3d2e8c420739","permalink":"https://stes.io/publication/stainnorm/","publishdate":"2017-09-14T00:00:00Z","relpermalink":"/publication/stainnorm/","section":"publication","summary":"While human observers are able to cope with variations in color and appearance of histological stains, digital pathology algorithms commonly require a well-normalized setting to achieve peak performance, especially when a limited amount of labeled data is available. This work provides a fully automated, end-to-end learning-based setup for normalizing histological stains, which considers the texture context of the tissue. We introduce Feature Aware Normalization, which extends the framework of batch normalization in combination with gating elements from Long Short-Term Memory units for normalization among different spatial regions of interest. By incorporating a pretrained deep neural network as a feature extractor steering a pixelwise processing pipeline, we achieve excellent normalization results and ensure a consistent representation of color and texture. The evaluation comprises a comparison of color histogram deviations, structural similarity and measures the color volume obtained by the different methods.","tags":null,"title":"Context-based Normalization of Histological Stains using Deep Convolutional Features","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"b546688203b14025f4c4b727b45df82f","permalink":"https://stes.io/talk/2012_neurips/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/talk/2012_neurips/","section":"talk","summary":"","tags":null,"title":"","type":"talk"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"3a8e786fb5cc989cf2b5b9748c374636","permalink":"https://stes.io/talk/2023_japan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/talk/2023_japan/","section":"talk","summary":"","tags":null,"title":"","type":"talk"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e39726d820441f1ee1f9886c53ddc51b","permalink":"https://stes.io/talk/2207_neuromatch/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/talk/2207_neuromatch/","section":"talk","summary":"","tags":null,"title":"","type":"talk"},{"authors":null,"categories":null,"content":"Test\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"966fac835a0eadb0b31900a8ba7347ca","permalink":"https://stes.io/talk/2302_mpfi-copy/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/talk/2302_mpfi-copy/","section":"talk","summary":"Mapping behavioral actions to neural activity is a fundamental goal of neuroscience. In this talk I will discuss CEBRA, a non-linear representation learning algorithm that jointly uses behavioral and neural data in a hypothesis- or discovery-driven manner to produce consistent, high-performance latent spaces. I will demonstrate our tool's utility for both calcium and electrophysiology datasets, across sensory and motor tasks, and in simple or complex behaviors across species.","tags":[],"title":"Learnable latent embeddings for joint behavioral and neural analysis","type":"talk"},{"authors":null,"categories":null,"content":"Test\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"888e273d07595f0b4f4ecb495469ff80","permalink":"https://stes.io/talk/2302_mpfi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/talk/2302_mpfi/","section":"talk","summary":"Mapping behavioral actions to neural activity is a fundamental goal of neuroscience. In this talk I will discuss CEBRA, a non-linear representation learning algorithm that jointly uses behavioral and neural data in a hypothesis- or discovery-driven manner to produce consistent, high-performance latent spaces. I will demonstrate our tool's utility for both calcium and electrophysiology datasets, across sensory and motor tasks, and in simple or complex behaviors across species.","tags":[],"title":"Learnable latent embeddings for joint behavioral and neural analysis","type":"talk"}]